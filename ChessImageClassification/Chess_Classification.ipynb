{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Libraries and Test Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "print(os.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(20) & 0xFF==ord('d'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = os.path.join('Datasets', 'SortedImages')\n",
    "CATEGORIES = [\"empty\",\"black_piece\", \"white_piece\"]\n",
    "COLLECT_IMAGES_PATH = os.path.join('Datasets', 'CollectedImages')\n",
    "IMG_SIZE=70\n",
    "number_imgs = 1\n",
    "\n",
    "if not os.path.exists(COLLECT_IMAGES_PATH):\n",
    "    !mkdir {COLLECT_IMAGES_PATH}\n",
    "    \n",
    "for category in CATEGORIES:\n",
    "    IMG_PATH = os.path.join(DATADIR, category)\n",
    "    if not os.path.exists(IMG_PATH):\n",
    "        !mkdir {IMG_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Capture Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate by finding corners of empty board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################\n",
    "HEIGHT = 560\n",
    "WIDTH = 560\n",
    "#################################################\n",
    "\n",
    "\n",
    "#--------------------------HELPERS----------------------------------------------\n",
    "def preprocess(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (3,3),1)\n",
    "    img_threshold = cv2.adaptiveThreshold(img_blur, 255,1,1,11,2)\n",
    "    return img_threshold\n",
    "\n",
    "def reorder(pts):\n",
    "    pts = pts.reshape((4,2))\n",
    "    new_pts = np.zeros((4,1,2))\n",
    "    sum = pts.sum(1)\n",
    "    new_pts[0] = pts[np.argmin(sum)]\n",
    "    new_pts[3] = pts[np.argmax(sum)]\n",
    "    diff = np.diff(pts,axis=1)\n",
    "    new_pts[1] = pts[np.argmin(diff)]\n",
    "    new_pts[2] = pts[np.argmax(diff)]\n",
    "    return new_pts\n",
    "\n",
    "def findBiggestContour(contours):\n",
    "    pts = np.array([])\n",
    "    max_area = 0\n",
    "    for i in contours:\n",
    "        area = cv2.contourArea(i)\n",
    "        if area > 50:\n",
    "            peri = cv2.arcLength(i, True)\n",
    "            approx = cv2.approxPolyDP(i,0.02*peri,True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                pts = approx\n",
    "                max_area = area\n",
    "    return reorder(pts), max_area\n",
    "\n",
    "def find_board_corners(img):\n",
    "    processed_img = preprocess(img)\n",
    "    contours, heirarchy = cv2.findContours(processed_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    biggest, maxArea = findBiggestContour(contours)\n",
    "    return biggest\n",
    "    \n",
    "def crop_board(img, corners):\n",
    "    original_img = np.float32(corners)\n",
    "    new_img = np.float32([[0, 0], [WIDTH, 0], [0, HEIGHT], [WIDTH, HEIGHT]])\n",
    "    matrix = cv2.getPerspectiveTransform(original_img, new_img)\n",
    "    imgWarpColored = cv2.warpPerspective(frame, matrix, (WIDTH, HEIGHT))\n",
    "    return imgWarpColored\n",
    "\n",
    "def get_cells(img):\n",
    "    rows = np.vsplit(img,8)\n",
    "    cells = [[],[],[],[],[],[],[],[]]\n",
    "    for r in range(8):\n",
    "        cols = np.hsplit(rows[r], 8)\n",
    "        for c in cols:\n",
    "            cells[r].append(c)\n",
    "    return cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibrate\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret,calibrate_img = cap.read()\n",
    "corners = find_board_corners(calibrate_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "    cv2.imshow('Video', crop_board(frame, corners))\n",
    "    if cv2.waitKey(20) & 0xFF==ord('d'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image 0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "for imgnum in range(number_imgs):\n",
    "    print('Collecting image {}'.format(imgnum))\n",
    "    ret, frame = cap.read()\n",
    "    frame = crop_board(frame, corners)\n",
    "    cv2.imshow('frame', frame)\n",
    "    cells = get_cells(frame)\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            imgname = os.path.join(COLLECT_IMAGES_PATH,'img.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "            cv2.imwrite(imgname, cells[i][j])\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "datagen = ImageDataGenerator(        \n",
    "        vertical_flip = True,\n",
    "        horizontal_flip = True,\n",
    "        brightness_range = (0.5, 1.5))\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "dataset = []\n",
    "AUGDIR = os.path.join('Datasets', 'AugmentedImages')\n",
    "DATADIR = os.path.join('Datasets', 'SortedImages')\n",
    "for category in CATEGORIES:\n",
    "    dataset = []\n",
    "    my_images = os.path.join(DATADIR, category)\n",
    "    for image_name in os.listdir(my_images):\n",
    "        image = io.imread(os.path.join(my_images,image_name))        \n",
    "        image = Image.fromarray(image, 'RGB')        \n",
    "        image = image.resize((IMG_SIZE,IMG_SIZE)) \n",
    "        dataset.append(np.array(image))\n",
    "    x = np.array(dataset)\n",
    "    \n",
    "    save_dir = os.path.join(AUGDIR, category)\n",
    "    if not os.path.exists(save_dir):\n",
    "        !mkdir {save_dir}\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=5,\n",
    "                              save_to_dir= save_dir,\n",
    "                              save_prefix='dr',\n",
    "                              save_format='jpg'):    \n",
    "        i += 1    \n",
    "        if i > 400:        \n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Read the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#At this point, move the collected images in the corresponding folders\n",
    "IMG_SIZE = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "AUGDIR = os.path.join('Datasets', 'AugmentedImages')\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exeption as e:\n",
    "                pass\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"ChessClassification-CNN-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomRotation(0.3),\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(IMG_SIZE,IMG_SIZE,3)),\n",
    "    layers.experimental.preprocessing.RandomFlip(\"vertical\", input_shape=(IMG_SIZE,IMG_SIZE,3)),\n",
    "    layers.experimental.preprocessing.RandomContrast(0.3),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "55/55 [==============================] - 14s 221ms/step - loss: 0.6089 - accuracy: 0.7184 - val_loss: 0.1345 - val_accuracy: 0.9909\n",
      "Epoch 2/12\n",
      "55/55 [==============================] - 10s 189ms/step - loss: 0.1285 - accuracy: 0.9681 - val_loss: 0.0558 - val_accuracy: 0.9727\n",
      "Epoch 3/12\n",
      "55/55 [==============================] - 10s 188ms/step - loss: 0.0590 - accuracy: 0.9886 - val_loss: 0.0223 - val_accuracy: 0.9954\n",
      "Epoch 4/12\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 0.0512 - accuracy: 0.9914 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 5/12\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 0.0400 - accuracy: 0.9903 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 6/12\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 0.0275 - accuracy: 0.9920 - val_loss: 0.0043 - val_accuracy: 0.9977\n",
      "Epoch 7/12\n",
      "55/55 [==============================] - 11s 191ms/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 0.0087 - val_accuracy: 0.9977\n",
      "Epoch 8/12\n",
      "55/55 [==============================] - 11s 194ms/step - loss: 0.0195 - accuracy: 0.9960 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 9/12\n",
      "55/55 [==============================] - 11s 193ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 10/12\n",
      "55/55 [==============================] - 11s 192ms/step - loss: 0.0187 - accuracy: 0.9960 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 11/12\n",
      "55/55 [==============================] - 11s 194ms/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 0.0329 - val_accuracy: 0.9909\n",
      "Epoch 12/12\n",
      "55/55 [==============================] - 10s 190ms/step - loss: 0.0356 - accuracy: 0.9892 - val_loss: 0.0030 - val_accuracy: 0.9977\n",
      "INFO:tensorflow:Assets written to: my_chess_model\\assets\n"
     ]
    }
   ],
   "source": [
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(data_augmentation)\n",
    "model.add(Conv2D(64, (3,3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size = 32, validation_split = 0.2, epochs = 12, callbacks = [tensorboard])\n",
    "\n",
    "model.save('my_chess_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "img = 'pred2.jpg'\n",
    "\n",
    "def prepare(filepath):\n",
    "    img_array = cv2.imread(filepath)\n",
    "    img_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "    return img_array.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "\n",
    "model = tf.keras.models.load_model('my_chess_model')\n",
    "\n",
    "# cv2.imshow('daefadf',im)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "prediction = model.predict([prepare(img)])\n",
    "\n",
    "print(prediction.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 2, 0, 0, 0, 0, 1, 1], [2, 2, 0, 0, 0, 0, 1, 1], [2, 2, 0, 0, 0, 0, 2, 1], [2, 0, 2, 0, 0, 0, 0, 1], [2, 0, 0, 2, 1, 0, 0, 1], [2, 2, 0, 0, 0, 0, 1, 1], [2, 2, 0, 0, 0, 0, 1, 1], [2, 2, 0, 0, 0, 0, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "ret,frame = capture.read()\n",
    "\n",
    "img = crop_board(frame,corners)\n",
    "cells = get_cells(img)\n",
    "\n",
    "board = [[None for i in range(8)] for j in range(8)]\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        cells[i][j] = cv2.resize(cells[i][j], (IMG_SIZE,IMG_SIZE))\n",
    "        prediction = model.predict([cells[i][j].reshape(-1,IMG_SIZE,IMG_SIZE,3)])\n",
    "        board[i][j] = prediction.argmax()\n",
    "\n",
    "print(board)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
